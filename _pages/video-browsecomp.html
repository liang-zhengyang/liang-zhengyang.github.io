---
layout: null
permalink: /video-browsecomp/
---
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-BrowseComp: Benchmarking Agentic Video Research on Open Web</title>
    
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    
    <!-- FontAwesome for Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <style>
        :root {
            --primary-color: #20c997;
            --secondary-color: #009879;
            --text-color: #333;
            --bg-color: #ffffff;
            --light-bg: #f8f9fa;
            --border-color: #dddddd;
            --best-color: #d63031;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            margin: 0;
            padding: 0;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        header {
            text-align: center;
            margin-bottom: 50px;
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 20px;
            color: #222;
        }

        .author-block {
            font-size: 1.1em;
            margin-bottom: 10px;
        }

        .affiliation-block {
            font-size: 0.95em;
            color: #666;
            margin-bottom: 30px;
        }

        .button-block {
            margin-top: 30px;
        }

        .btn {
            display: inline-block;
            padding: 12px 24px;
            margin: 5px;
            border-radius: 30px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s ease;
            font-size: 1em;
        }

        .btn-primary { background-color: #007bff; color: white; }
        .btn-success { background-color: #28a745; color: white; }
        .btn-info { background-color: #17a2b8; color: white; }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.15);
            opacity: 0.9;
        }

        h2 {
            border-bottom: 2px solid var(--primary-color);
            padding-bottom: 10px;
            margin-top: 40px;
            color: #222;
        }

        .abstract-box {
            background-color: var(--light-bg);
            border-left: 5px solid var(--primary-color);
            padding: 25px;
            margin: 20px 0;
            border-radius: 4px;
            text-align: justify;
        }

        .leaderboard-container {
            overflow-x: auto;
            margin: 30px 0;
        }

        .leaderboard-table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.95em;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
        }

        .leaderboard-table thead tr {
            background-color: var(--secondary-color);
            color: #ffffff;
            text-align: center;
        }

        .leaderboard-table th,
        .leaderboard-table td {
            padding: 15px;
            text-align: center;
            border-bottom: 1px solid var(--border-color);
        }

        .leaderboard-table tbody tr:nth-of-type(even) {
            background-color: #f9f9f9;
        }

        .leaderboard-table tbody tr:last-of-type {
            border-bottom: 2px solid var(--secondary-color);
        }

        .leaderboard-table tbody tr:hover {
            background-color: #f1f1f1;
            transition: background-color 0.2s ease;
        }

        .best-score {
            font-weight: bold;
            color: var(--best-color);
        }

        .category-header {
            text-align: left !important;
            background-color: #eee;
            font-weight: bold;
        }

        pre {
            background-color: #272822;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            font-size: 0.9em;
        }

        footer {
            text-align: center;
            margin-top: 60px;
            padding-top: 20px;
            border-top: 1px solid var(--border-color);
            color: #888;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            h1 { font-size: 1.8em; }
            .btn { width: 100%; box-sizing: border-box; }
        }
    </style>
</head>
<body>

<div class="container">
    <header>
        <h1>Video-BrowseComp: Benchmarking Agentic Video Research on Open Web</h1>
        
        <div class="author-block">
            <strong>Zhengyang Liang<sup>1,♣</sup>, Yan Shu<sup>2,♣</sup>, Xiangrui Liu<sup>3</sup>, Minghao Qin<sup>3</sup>, Kaixin Liang<sup>4</sup>, Paolo Rota<sup>2</sup>, Nicu Sebe<sup>2</sup>, Zheng Liu<sup>5</sup>, Lizi Liao<sup>1</sup></strong>
        </div>

        <div class="affiliation-block">
            <sup>1</sup>Singapore Management University, <sup>2</sup>University of Trento, <br>
            <sup>3</sup>Beijing Academy of Artificial Intelligence, <sup>4</sup>Beijing University of Posts and Telecommunications, <br>
            <sup>5</sup>Hong Kong Polytechnic University
        </div>

        <div class="button-block">
            <a href="https://arxiv.org/abs/2504.12516" class="btn btn-primary"><i class="fas fa-file-pdf"></i> Paper</a>
            <a href="https://huggingface.co/datasets/chr1ce/Video-Browsecomp" class="btn btn-info"><i class="fas fa-database"></i> Benchmark</a>
        </div>
    </header>

    <section id="abstract">
        <h2>Abstract</h2>
        <div class="abstract-box">
            The evolution of autonomous agents is redefining information seeking, transitioning from passive retrieval to proactive, open-ended web research. However, while textual and static multimodal agents have seen rapid progress, a significant modality gap remains in the web's most dynamic modality: video. Existing video benchmarks predominantly focus on passive perception, feeding curated clips to models without requiring external retrieval. They fail to evaluate agentic video research, which necessitates actively interrogating video timelines, cross-referencing dispersed evidence, and verifying claims against the open web. 
            <br><br>
            To bridge this gap, we present <strong>Video-BrowseComp</strong>, a challenging benchmark comprising 210 questions tailored for open-web agentic video reasoning. Unlike prior benchmarks, Video-BrowseComp enforces a mandatory dependency on temporal visual evidence, ensuring that answers cannot be derived solely through text search but require navigating video timelines to verify external claims. Our evaluation of state-of-the-art models reveals a critical bottleneck: even advanced search-augmented models like GPT-5.1 (w/ Search) achieve only 23.81% accuracy. Our analysis reveals that these models largely rely on textual proxies, excelling in metadata-rich domains (e.g., TV shows with plot summaries) but collapsing in metadata-sparse, dynamic environments (e.g., sports, gameplay) where visual grounding is essential. As the first open-web video research benchmark, Video-BrowseComp advances the field beyond passive perception toward proactive video reasoning.
        </div>
    </section>

    <section id="leaderboard">
        <h2>Leaderboard</h2>
        <p>We evaluate state-of-the-art models on Video-BrowseComp. The accuracy (%) is reported for Overall (OA) and three difficulty levels (Level 1, Level 2, Level 3).</p>
        
        <div class="leaderboard-container">
            <table class="leaderboard-table">
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>Overall Acc (%)</th>
                        <th>Level 1 (%)</th>
                        <th>Level 2 (%)</th>
                        <th>Level 3 (%)</th>
                        <th>Calibration Error (%)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="category-header"><td colspan="6">Tool-Free Models</td></tr>
                    <tr><td>Qwen3-VL-8B-Thinking</td><td>7.14</td><td>12.00</td><td>0.00</td><td>0.00</td><td>52.49</td></tr>
                    <tr><td>Qwen3-VL-235B-A22B-Instruct</td><td>13.33</td><td>22.40</td><td>0.00</td><td>0.00</td><td>77.64</td></tr>
                    <tr><td>GLM-4.6V</td><td>10.95</td><td>16.80</td><td>3.23</td><td>0.00</td><td>44.40</td></tr>
                    <tr><td>gpt-4o-2024-11-20</td><td>17.62</td><td>28.00</td><td>3.23</td><td>0.00</td><td>58.81</td></tr>
                    <tr><td>gpt-4o-mini-2024-07-18</td><td>9.52</td><td>16.00</td><td>0.00</td><td>0.00</td><td>63.55</td></tr>
                    <tr><td>gpt-5-mini-2025-08-07</td><td>15.71</td><td>26.40</td><td>0.00</td><td>0.00</td><td>37.47</td></tr>
                    <tr><td>gemini-2.5-flash-2025-06</td><td>16.67</td><td>27.20</td><td>1.61</td><td>0.00</td><td>77.79</td></tr>
                    <tr><td>gemini-2.5-pro-2025-06</td><td>19.52</td><td>31.20</td><td>3.23</td><td>0.00</td><td>79.18</td></tr>
                    
                    <tr class="category-header"><td colspan="6">Search Models</td></tr>
                    <tr><td>gemini-2.5-flash-2025-06 (w/ Search)</td><td>20.95</td><td>32.80</td><td>4.84</td><td>0.00</td><td>35.98</td></tr>
                    <tr><td>gemini-2.5-pro-2025-06 (w/ Search)</td><td><span class="best-score">23.81</span></td><td><span class="best-score">37.60</span></td><td>4.84</td><td>0.00</td><td>31.45</td></tr>
                    <tr><td>gpt-5.1-2025-11-13 (w/ Search)</td><td>15.24</td><td>21.60</td><td>6.45</td><td>4.35</td><td><span class="best-score">30.20</span></td></tr>
                    <tr><td>o4-mini-deep-research-2025-06-26</td><td>22.86</td><td>30.40</td><td><span class="best-score">12.90</span></td><td><span class="best-score">8.70</span></td><td>42.55</td></tr>
                </tbody>
            </table>
        </div>
    </section>

    <section id="citation">
        <h2>Citation</h2>
        <pre><code>@misc{liang2025videobrowsecompbenchmarkingagenticvideo,
      title={Video-BrowseComp: Benchmarking Agentic Video Research on Open Web}, 
      author={Zhengyang Liang and Yan Shu and Xiangrui Liu and Minghao Qin and Kaixin Liang and Paolo Rota and Nicu Sebe and Zheng Liu and Lizi Liao},
      year={2025},
      eprint={2512.23044},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2512.23044}, 
}</code></pre>
    </section>

    <footer>
        &copy; 2025 Video-BrowseComp Team. All rights reserved.
    </footer>
</div>

<script>
    // Example of JS code: Log a message when a button is clicked
    document.querySelectorAll('.btn').forEach(button => {
        button.addEventListener('click', () => {
            console.log('Button clicked: ' + button.innerText);
        });
    });
</script>

</body>
</html>
